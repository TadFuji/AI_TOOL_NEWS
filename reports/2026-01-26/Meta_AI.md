# 1. Top Tier - Daily Report

## Meta AI
- Post: Answering a question whose answer you've learned by heart is very different from understanding the underlying reality. Given any question, an LLM can be trained to answer it correctly. The question is whether a system can answer a question of a type it's never faced before.
- Time: 2026-01-25 22:37
- URL: https://x.com/ylecun/status/2015554654214455805

- Post: I've been wondering about that too ðŸ¤”
- Time: 2026-01-25 20:16
- URL: https://x.com/ylecun/status/2015519204200374294

- Post: No. I'm saying several things but not that. I'm saying 1. ***auto-regressive*** LLMs don't reason and don't plan 2. LLMs with token sequence search bolted on top can inefficiently perform reasoning for domain where reasoning can be done in token space (essentially math and code) 3. Actual planning and reasoning requires a search over answers/outputs (by energy minimization). This (a) requires a ***world model*** (LLMs are not it), and (b) is much better done by optimization in continuous space than through combinatorial search in discrete token sequence space. 4. World models that apply to real-world data cannot use generative architectures like LLMs. Because the real world is too messy, noisy, and unpredictable.
- Time: 2026-01-25 20:05
- URL: https://x.com/ylecun/status/2015516355433283964

- Post: My slide pertains to auto-regressive token prediction and is correct. Test-time compute is a ridiculously expensive and inefficient way to mitigate the problem I mention in my slide.
- Time: 2026-01-25 19:51
- URL: https://x.com/ylecun/status/2015512899892994396

- Post: Do you have data?
- Time: 2026-01-25 19:45
- URL: https://x.com/ylecun/status/2015511283705970767

- Post: Yet you follow me. LOL.
- Time: 2026-01-25 19:43
- URL: https://x.com/ylecun/status/2015510930621153368

- Post: Trump is just the trigger. There are deep historical forces: The dismantling of the FCC fairness doctrine by Reagan, the resulting emergence of Fox News, conservative talk radio, and other propaganda outlets, the removal of guardrails for the influence of money in politics (e.g. Citizen United), the continuous reduction of taxes on high incomes, the ever-increasing wealth and income inequalities enabled by the above, the stagnation of working class income despite continued increase in productivity (and corporate profits), the total lack of social protection and benefits compared to other developed countries. People in the middle class and below have been screwed for 40 years and are angry. They should be angry at Republicans. But the Republican party has managed to deflect their anger towards immigrants, non-Christians, non-whites, liberals, LGBT, China, academia, intellectual "elites", scientists, journalists, and non-existent scarecrows like Antifa.
- Time: 2026-01-25 19:02
- URL: https://x.com/ylecun/status/2015500514708902306

- Post: Because their purpose is to steal the election.
- Time: 2026-01-25 16:41
- URL: https://x.com/ylecun/status/2015465156994539679

- Post: You are an idiot. I don't have time to argue with idiots.
- Time: 2026-01-25 16:41
- URL: https://x.com/ylecun/status/2015464975599341803

- Post: There is nothing wrong with this slide. It talks about ***auto-regressive token prediction*** Reasoning models produce multiple token sequences and ***search*** for a good one, as evaluated by a separate model. That no longer constitutes strict auto-regressive token prediction. In my talks, I argue that reasoning should be performed by search/optimization. That's the whole idea of energy-based models, which I've been advocating for for 20 years. Token sequence selection is a *very primitive* and super-inefficient form of reasoning-by-search. It works ok for math and code, but for almost nothing else.
- Time: 2026-01-25 16:38
- URL: https://x.com/ylecun/status/2015464359829389350

No recent posts from @MetaAI.
