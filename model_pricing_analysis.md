# xAI Grok モデル比較とコストパフォーマンス分析

## 1. 利用可能なモデル一覧 (2026年1月現在)
APIより取得したモデルID一覧です。

- **Flagship (高性能)**
    - `grok-4-0709` (grok-4-latest)
    - `grok-3`
- **Fast / Efficiency (高コスパ・高速)**
    - `grok-4-1-fast-reasoning`
    - `grok-4-1-fast-non-reasoning`
    - `grok-4-fast-reasoning`
    - `grok-4-fast-non-reasoning`
    - `grok-3-mini`
- **Specialized**
    - `grok-2-vision-1212` (画像認識)

## 2. 料金比較 (100万トークンあたり)

| モデルカテゴリ | モデル名 | 入力 (Input) | 出力 (Output) | 特徴 |
| :--- | :--- | :--- | :--- | :--- |
| **Flagship** | `grok-4` | **$3.00** | **$15.00** | 推論能力最高、高価。複雑なタスク向け。 |
| **Standard** | `grok-3` | $3.00 | $15.00 | 旧フラッグシップ。価格はGrok-4と同じ。 |
| **Mini** | `grok-3-mini` | $0.30 | $0.50 | 軽量版。 |
| **Fast (推奨)** | **`grok-4-fast`** | **$0.20** | **$0.50** | **圧倒的コスパ。Grok-4比で入力1/15、出力1/30。** |

※ツール利用料（検索等）は別途 1,000回あたり数ドル程度（要確認）かかる場合がありますが、モデル自体のトークンコスト差が支配的です。

## 3. 推奨モデル (Best Cost-Performance)

**結論: `grok-4-1-fast-non-reasoning` または `grok-4-1-fast-non-reasoning`**

### 理由
1.  **圧倒的な安さ**: フラッグシップモデルに比べて **約93%〜96% オフ** という破格の安さです。ニュース収集で大量のテキスト（検索結果のツイートなど）を読み込ませる場合、Inputコストの安さが効いてきます。
2.  **基本性能の高さ**: "Grok-4" 世代の軽量版であり、ニュースの要約程度であれば十分すぎる性能を持っています。
3.  **Context Window**: 200万トークン（！）という広大なコンテキストサイズを持ち、大量の情報を一度に処理できます。

### 構成案
- **ニュース収集・要約**: `grok-4-fast` 系を使用。
- **検索 (x_search)**: 検索ツール自体はモデルを問わず利用可能です（API仕様上）。

まずは **`grok-4-1-fast-non-reasoning`**（最も高速・安価）でシステムを組み、品質に不足があれば `reasoning` 版や `grok-4-latest` に切り替えるアプローチが最も賢明です。
