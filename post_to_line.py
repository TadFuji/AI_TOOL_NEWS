import os
import glob
import datetime
import re
from dotenv import load_dotenv
from linebot.v3.messaging import (
    Configuration,
    ApiClient,
    MessagingApi,
    MessagingApi,
    PushMessageRequest,
    BroadcastRequest,
    TextMessage,
)

# Load environment variables
load_dotenv()

# Configuration
REPORTS_DIR = "reports"
SITE_URL = "https://tadahikof.github.io/AI_TOOL_NEWS/"  # Adjust to your actual Pages URL

def get_latest_report_items():
    """Finds today's report and extracts news items."""
    # TIMEZONE FIX: GitHub Actions runs in UTC. Force JST (UTC+9)
    JST = datetime.timezone(datetime.timedelta(hours=9))
    today_str = datetime.datetime.now(JST).strftime("%Y-%m-%d")
    
    # Also check yesterday just in case of boundary issues, but prioritize today
    target_dirs = [today_str]
    
    all_items = []
    
    today_folder = os.path.join(REPORTS_DIR, today_str)
    
    # User Request: RSS General News ONLY (No Tool Updates)
    # Collected at 7:00 AM, covering previous 24h.
    # We only look at 'general_news' subfolder in today's report dir.
    
    target_path = os.path.join(today_folder, "general_news", "*.md")
    files = glob.glob(target_path)
    
    all_items = []
    for fpath in files:
        items = parse_report_file(fpath)
        all_items.extend(items)
    
    return all_items, today_str

def parse_report_file(filepath):
    """Parses a markdown report to extract news items (Same logic as post_to_x)."""
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()

    # Split by tool sections (## ToolName)
    sections = re.split(r'^## ', content, flags=re.MULTILINE)[1:]
    
    items = []
    for section in sections:
        lines = section.strip().split('\n')
        tool_name = lines[0].strip()
        body_text = "\n".join(lines[1:]).strip()

        if "Updates not found" in body_text or "No significant news" in body_text or not body_text:
            continue
        
        summary_match = re.search(r'(?:- )?\*\*Summary\*\*:? (.*)', body_text)
        url_match = re.search(r'(?:- )?\*\*URL\*\*:? (.*)', body_text)
        
        if summary_match:
            summary = summary_match.group(1).strip().replace("**", "")
            items.append(f"ğŸ”¹ {tool_name}\n{summary[:50]}...") # Truncate for LINE readability
            
    return items

def send_line_message(message_text):
    """Sends a push message to LINE."""
    token = os.environ.get("LINE_CHANNEL_ACCESS_TOKEN")
    user_id = os.environ.get("LINE_USER_ID")
    
    if not token or not user_id:
        print("Skipping LINE post: Missing credentials.")
        return

    configuration = Configuration(access_token=token)
    try:
        with ApiClient(configuration) as api_client:
            line_bot_api = MessagingApi(api_client)
            
            # BROADCAST MODE (Send to ALL followers)
            # Was: PushMessageRequest(to=user_id, ...)
            broadcast_request = BroadcastRequest(
                messages=[TextMessage(text=message_text)]
            )
            line_bot_api.broadcast(broadcast_request)
            print("Successfully sent LINE BROADCAST message.")
    except Exception as e:
        print(f"Failed to send LINE message: {e}")

import google.generativeai as genai

def select_top_news_with_gemini(all_items):
    """Uses Gemini 3 Flash to curate the top 10 most important news."""
    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        print("âš ï¸ No GEMINI_API_KEY found. Falling back to simple selection.")
        return all_items[:10]

    print(f"ğŸ§  Asking Gemini 3 Flash to curate {len(all_items)} items...")
    
    # Configure Gemini
    genai.configure(api_key=api_key)
    # User requested specific model: Gemini 3 Flash Preview
    # Note: If this specific model ID is not yet active in region, standard flash might be used.
    # We will try the user's requested ID, fallback to 'gemini-2.0-flash-exp' if 3 is not out 
    # (But based on search, 3 is available).
    model_name = 'gemini-3-flash-preview' 
    
    try:
        model = genai.GenerativeModel(model_name)
        
        # Prepare content for AI
        news_text = "\n\n".join(all_items)
        
        prompt = (
            "Role: æ•è…•ãƒ“ã‚¸ãƒã‚¹èªŒç·¨é›†é•· (Target: æ—¥æœ¬ã®40ä»£ãƒ“ã‚¸ãƒã‚¹ãƒ‘ãƒ¼ã‚½ãƒ³ãƒ»ä¸€èˆ¬å±¤)\n"
            "Task: ä»¥ä¸‹ã®AIãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒªã‚¹ãƒˆã‹ã‚‰ã€ã€Œä»Šã®æ™‚ä»£ã‚’ç”Ÿãã‚‹å¤§äººã«ã¨ã£ã¦ã€æœ¬å½“ã«çŸ¥ã£ã¦ãŠãã¹ããƒˆãƒƒãƒ—10ã€ã‚’å³é¸ã—ã¦ãã ã•ã„ã€‚\n\n"
            "ã€é¸å®šåŸºæº– - Selection Criteriaã€‘\n"
            "1. **ç¤¾ä¼šçš„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ**: ä»•äº‹ã®ã‚„ã‚Šæ–¹ã€ç”Ÿæ´»ã€ç¤¾ä¼šã®ãƒ«ãƒ¼ãƒ«ã‚’å¤‰ãˆã‚‹ã‚ˆã†ãªãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æœ€å„ªå…ˆï¼ˆä¾‹: ChatGPTã®æ–°æ©Ÿèƒ½ã€Googleã®é©å‘½çš„ç™ºè¡¨ï¼‰ã€‚\n"
            "2. **å®Ÿç”¨æ€§**: ã€Œæ˜æ—¥ã‹ã‚‰è‡ªåˆ†ã®ä»•äº‹ã‚„ç”Ÿæ´»ã«ä½¿ãˆã‚‹ã‹ï¼Ÿã€ã‚’é‡è¦–ã€‚ãƒãƒ‹ã‚¢ãƒƒã‚¯ãªé–‹ç™ºè€…å‘ã‘ãƒ„ãƒ¼ãƒ«ï¼ˆAPIã®å¾®ç´°ãªå¤‰æ›´ã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæ›´æ–°ãªã©ï¼‰ã¯æ€ã„åˆ‡ã£ã¦é™¤å¤–ã—ã¦ãã ã•ã„ã€‚\n"
            "3. **ãƒˆãƒ¬ãƒ³ãƒ‰**: ã€Œä»Šã€ä¸–ã®ä¸­ã§ä½•ãŒèµ·ãã¦ã„ã‚‹ã‹ã€ã‚’æŠŠæ¡ã§ãã‚‹å¤§ããªå‹•ãã€‚\n\n"
            "ã€åŸ·ç­†ã‚¹ã‚¿ã‚¤ãƒ« - Tone & Styleã€‘\n"
            "ãƒ»40ä»£ã®çŸ¥çš„ãªå¤§äººã«å‘ã‘ãŸã€è½ã¡ç€ã„ãŸãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªæ—¥æœ¬èªã€‚\n"
            "ãƒ»å°‚é–€ç”¨èªã¯å™›ã¿ç •ãã€ã€Œãªãœãã‚ŒãŒå‡„ã„ã®ã‹ã€ã€Œã©ã†å½¹ã«ç«‹ã¤ã®ã‹ã€ã¨ã„ã†**æ„å‘³ï¼ˆImplicationï¼‰**ã‚’è§£èª¬ã—ã¦ãã ã•ã„ã€‚\n\n"
            "ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘\n"
            "å¿…ãšä»¥ä¸‹ã®å½¢å¼ã§ãƒˆãƒƒãƒ—10ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n\n"
            "1. **ã‚­ãƒ£ãƒƒãƒãƒ¼ãªè¦‹å‡ºã—** (ãƒ„ãƒ¼ãƒ«å)\n"
            "   æ¦‚è¦: [ä½•ãŒèµ·ããŸã®ã‹ã€ç°¡æ½”ã«]\n"
            "   ğŸ’¡ è¦–ç‚¹: [ãªãœã“ã‚ŒãŒé‡è¦ãªã®ã‹ï¼Ÿãƒ“ã‚¸ãƒã‚¹ã‚„ç”Ÿæ´»ã¸ã®å½±éŸ¿ã¯ï¼Ÿ]\n"
            "\n"
            "(ä»¥ä¸‹ã€10ä½ã¾ã§ç¶šã‘ã‚‹)\n\n"
            "News List:\n"
            f"{news_text[:35000]}" # Increased limit slightly for context
        )
        
        response = model.generate_content(prompt)
        
        if response and response.text:
            print("âœ… Gemini curation successful!")
            return [response.text.strip()] # Return as a single pre-formatted string block
            
    except Exception as e:
        print(f"âŒ Gemini Curation Failed: {e}")
        return all_items[:10] # Fallback

    return all_items[:10]

def main():
    # TIMEZONE FIX: GitHub Actions runs in UTC. Force JST (UTC+9)
    JST = datetime.timezone(datetime.timedelta(hours=9))
    now_jst = datetime.datetime.now(JST)
    
    print(f"Current JST Time: {now_jst.strftime('%H:%M')}")
    
    # Only run at 7:00 AM 
    if now_jst.hour != 7:
        print("ğŸ•’ Not 7:00 AM JST. Skipping LINE post.")
        return

    print("=== LINE Auto-Post Start ===")
    
    items, date_str = get_latest_report_items()
    
    if not items:
        print("No news items found for today.")
        return

    # AI Curation Step
    # If using AI, we get a single string block. If fallback, we get list.
    curated_content = select_top_news_with_gemini(items)
    
    # Construct Message
    msg = f"ğŸ“… {date_str} AI News Digest (AI Selected)\n\n"
    
    if isinstance(curated_content, list) and len(curated_content) == 1 and "\n" in curated_content[0]:
        # It's the AI text block
        msg += curated_content[0]
    else:
        # Fallback list
        msg += "\n\n".join(curated_content)
    
    # Footer
    msg += f"\n\nğŸ”— Full Report:\n{SITE_URL}"
    
    print("Generated Message:")
    print(msg)
    
    send_line_message(msg)
    print("=== LINE Auto-Post Complete ===")

if __name__ == "__main__":
    main()
